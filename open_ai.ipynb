{
 "cells": [
  {
   "cell_type": "code",
   "id": "59ba4ce097c8d230",
   "metadata": {},
   "source": [
    "import os, json, requests, yaml\n",
    "from openai import OpenAI\n",
    "from datetime import datetime"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "c0adc12766c52870",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "source": [
    "# Load API key from config file\n",
    "with open('config.yaml', 'r') as f:\n",
    "    config = yaml.safe_load(f)\n",
    "    api_key = config['api_key']\n",
    "\n",
    "client = OpenAI(api_key=api_key)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "ce723187b2081dec",
   "metadata": {},
   "source": [
    "NOW = datetime.now()\n",
    "FORMATTED_TIME = NOW.strftime(\"%Y-%m-%d_%H-%M-%S\")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "64819863b0f844f2",
   "metadata": {},
   "source": [
    "from pydantic import BaseModel, Field\n",
    "from typing import Literal, List, Optional\n",
    "\n",
    "class ChannelBelief(BaseModel):\n",
    "    channel: Literal[\"Revenue\", \"Cost\", \"Labor\"] = Field(\n",
    "        ...,\n",
    "        description=\"Economic channel affected by data or AI use\"\n",
    "    )\n",
    "    belief: Literal[\"increase\", \"decrease\", \"uncertain\"] = Field(\n",
    "        ...,\n",
    "        description=\"Direction of expected effect on the channel\"\n",
    "    )\n",
    "    confidence: float = Field(\n",
    "        ...,\n",
    "        ge=0, le=1,\n",
    "        description=\"Subjective confidence level (0–1) in the stated direction\"\n",
    "    )\n",
    "    magnitude: float = Field(\n",
    "        ...,\n",
    "        ge=0, le=1,\n",
    "        description=\"Expected strength or intensity (0–1) of the effect\"\n",
    "    )\n",
    "    explanation: str = Field(\n",
    "        ...,\n",
    "        description=\"Short reasoning (≤25 words) summarizing textual evidence\"\n",
    "    )"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "aff2f8efbe375a4c",
   "metadata": {},
   "source": [
    "def send_webhook_start(time):\n",
    "    try:\n",
    "        requests.post(\"https://ntfy.sh/earningstranscriptextractor27337\",\n",
    "                     data=f\"Started extractor at {time}.\",\n",
    "                     timeout=10)\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "\n",
    "def send_webhook_finish(time):\n",
    "    try:\n",
    "        requests.post(\"https://ntfy.sh/earningstranscriptextractor27337\",\n",
    "                     data=f\"Finished extracting data at {time}.\",\n",
    "                     timeout=10)\n",
    "    except Exception as e:\n",
    "        print(e)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "4f3d75572519878",
   "metadata": {},
   "source": [
    "def get_instruction(channel):\n",
    "    \"\"\"Generate channel-specific instruction\"\"\"\n",
    "    channel_descriptions = {\n",
    "        \"Revenue\": \"Revenue growth\",\n",
    "        \"Cost\": \"Cost efficiency\",\n",
    "        \"Labor\": \"Labor demand\"\n",
    "    }\n",
    "    \n",
    "    return f\"\"\"You are a **financial analyst** evaluating a firm's disclosure or communication.\n",
    "Based **only on this passage**, assess how the **firm's use of data or AI** is **expected to influence its *future performance*** — not its current nor past states— specifically through the **{channel_descriptions[channel]}** channel.\n",
    "\n",
    "Focus on *expectations* or *forward-looking implications* derived from the text\n",
    "(e.g., management plans, announced initiatives, strategic direction, or investor sentiment).\n",
    "Ignore purely descriptive mentions of existing data holdings or past performance unless they imply future impact.\n",
    "\n",
    "**IMPORTANT:** You must provide an analysis specifically for the **{channel}** channel.\n",
    "\"\"\"\n",
    "\n",
    "def get_prompt(channel):\n",
    "    \"\"\"Generate channel-specific prompt\"\"\"\n",
    "    return f\"\"\"For the **{channel}** channel, provide an analysis **strictly in the format below**:\n",
    "\n",
    "Channel: {channel}\n",
    "Belief: [increase / decrease / uncertain]\n",
    "Confidence: [0–1]\n",
    "Magnitude: [0–1]\n",
    "Explanation (≤ 100 words): [concise reasoning based on how data or AI use is expected to affect future outcomes]\n",
    "\n",
    "**Guidelines:**\n",
    "- **Belief** → Directional expectation (e.g., \"increase\" = expected positive impact on the {channel} channel).\n",
    "- **Confidence** → How strongly the text supports that direction.\n",
    "- **Magnitude** → Expected size or intensity of the effect.\n",
    "- **Explanation** → Key textual evidence linking data/AI use to the {channel} channel's expected change.\n",
    "\n",
    "**Goal:**\n",
    "Quantify **investor-style expectations** about how **data and AI as production factors** are expected to affect the firm's *future {channel.lower()} outcomes*.\n",
    "\"\"\"\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "def extract_belief(transcript, channel):\n",
    "    \"\"\"Extract belief for a specific channel\"\"\"\n",
    "    instruction = get_instruction(channel)\n",
    "    prompt = get_prompt(channel)\n",
    "    \n",
    "    response = client.responses.parse(\n",
    "        model=\"gpt-5-mini\",\n",
    "        instructions=instruction,\n",
    "        reasoning={\n",
    "        \"effort\": \"medium\"},\n",
    "        text={\n",
    "        \"verbosity\": \"high\"},\n",
    "        input=[\n",
    "            {\n",
    "                \"role\": \"user\",\n",
    "                \"content\": [\n",
    "                    {\n",
    "                        \"type\": \"input_text\",\n",
    "                        \"text\": f\"{prompt}\\n\"\n",
    "                    },\n",
    "                    {\n",
    "                        \"type\": \"input_text\",\n",
    "                        \"text\": f\"\\nHere is the transcript:\\n{transcript}\"\n",
    "                    }\n",
    "                ]\n",
    "            },\n",
    "        ],\n",
    "        text_format=ChannelBelief,\n",
    "    )\n",
    "\n",
    "    return response.output_parsed"
   ],
   "id": "dcd50a526145bf6",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "def save_output_json(filename, channels_list):\n",
    "    \"\"\"Save all three channel analyses to a single JSON file\"\"\"\n",
    "    output_data = {\n",
    "        \"channels\": [channel.model_dump() for channel in channels_list]\n",
    "    }\n",
    "    with open(f\"output/{filename}_{FORMATTED_TIME}_parsed.json\", \"w\") as f:\n",
    "        json.dump(output_data, f, indent=4)"
   ],
   "id": "cf4c433945254c0a",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "d0a4ceb162dff4aa",
   "metadata": {},
   "source": [
    "folder_path = \"transcripts\"\n",
    "output_path = \"output\"\n",
    "channels = [\"Revenue\", \"Cost\", \"Labor\"]\n",
    "\n",
    "send_webhook_start(FORMATTED_TIME)\n",
    "\n",
    "for filename in os.listdir(folder_path):\n",
    "    if filename.endswith(\".md\"):\n",
    "        file_path = os.path.join(folder_path, filename)\n",
    "\n",
    "        with open(file_path, \"r\", encoding=\"utf-8\") as file:\n",
    "            content = file.read()\n",
    "\n",
    "        # Call API three times, once for each channel\n",
    "        channel_results = []\n",
    "        for channel in channels:\n",
    "            print(f\"Processing {filename} for {channel} channel...\")\n",
    "            result = extract_belief(content, channel)\n",
    "            channel_results.append(result)\n",
    "        \n",
    "        # Save all three channels in one file\n",
    "        save_output_json(filename, channel_results)\n",
    "        print(f\"Completed {filename}\")\n",
    "\n",
    "finish = datetime.now()\n",
    "finish_time = NOW.strftime(\"%Y-%m-%d_%H-%M-%S\")\n",
    "send_webhook_finish(finish_time)"
   ],
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "SDK-Research",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
